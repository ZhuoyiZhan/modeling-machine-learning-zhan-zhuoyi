---
title: "HW7-ZhanZ"
author: "Zhan, Zhuoyi"
date: "`r date()`"
output: github_document
---

Use the Keras library to re-implement the simple neural network discussed during lecture for the mixture data (see nnet.R). Use a single 10-node hidden layer; fully connected.

```{r}
#install.packages("keras")
library(keras)
```

```{r}
#install.packages('rgl')
library('rgl')
library('nnet')
library('dplyr')
```

```{r}

library(devtools)
install_url("https://cran.r-project.org/src/contrib/Archive/ElemStatLearn/ElemStatLearn_2015.6.26.tar.gz")
```

```{r}
library('ElemStatLearn')
data(mixture.example)
```

```{r}
dat <- mixture.example
```

```{r}
fit <- nnet(x=dat$x, y=dat$y, size=10,entropy=TRUE, decay=0)

```

```{r}
dim(dat$x)
head(dat$x)
n <- dat$x
```



```{r}
range01 <- function(x){(x-min(x))/(max(x)-min(x))}
xtrain <- range01(dat$x)
xtest <- range01(dat$px1)
```

```{r}
xtrain
```


```{r}
model <- keras_model_sequential()
model %>%
  layer_flatten(input_shape = 2) %>%
  layer_dense(units = 10, activation = 'relu') %>%
  layer_dense(units = 10, activation = 'softmax')
```


```{r}
model %>% compile(
  optimizer = 'adam', 
  loss = 'sparse_categorical_crossentropy',
  metrics = c('accuracy')
)
```


```{r}
model %>% fit(xtrain, dat$y, epochs = 5, verbose = 2)
```









